### netty 介绍 demo

[TOC]



#### [netty简介 https://www.jianshu.com/p/b9f3f6a16911](https://www.jianshu.com/p/b9f3f6a16911)

#### nettty跟原声nio相比优点:

1，API使用简单，开发门槛低。

2，功能强大，预置了多种编解码功能，支持多种主流协议。

3，定制能力强，通过channelHandler对通信框架进行灵活扩展。

4，性能高。

5，成熟，稳定，修复了所有的jdk nio bug.

6，社区活跃。

7，经历了大规模的商业应用考验，质量得到验证。

#### 各种io比较说明

|  属性  |	同步阻塞io|  伪异步io  | 非阻塞nio1.4|   	异步io1.7 |
|:-----------:|:-----------:|:-----------:|:-----------:|:-----------:|
|客户端个数-线程  |	  1       |    n    |  	  1    |     		0 |
|io类型-阻塞     |	true      |  	true|  false   |		false |
|io类型-异步     |	true      |  	true|    	fal| false |
|api难度         |   简单     |   简单    |   非常复杂   |  复杂 |
|调试难度          |简单        |简单       |复杂        |复杂 |
|可靠性           |非常差       |  差      |   高      |   高 |
|吞吐量           | 低        |    中    |     高    |     高 |

#### 服务端例子

```java
public class NettyServer {
    public static void main(String[] args) {
        ServerBootstrap serverBootstrap = new ServerBootstrap();

        //boos对应，IOServer.java中的接受新连接线程，主要负责创建新连接
        //worker对应 IOServer.java中的负责读取数据的线程，主要用于读取数据以及业务逻辑处理
        //NioEventLoopGroup其实就是一个实现了Java ExecutorService的线程池，
        // 其中的线程数可定制，若不设置线程数参数，则该参数值默认为2 * CPU核数量，
        NioEventLoopGroup bossGroup = new NioEventLoopGroup();
        NioEventLoopGroup workerGroup = new NioEventLoopGroup();
        OioEventLoopGroup bossGroupO = new OioEventLoopGroup();
        OioEventLoopGroup workerGroupO = new OioEventLoopGroup();
        serverBootstrap
                .group(bossGroup, workerGroup)          //指定线程模型 连接建立完成以后由 主线程 对应的acceptor将后续的数据处理分发给 子反应组 （subReactor）进行处理
                .channel(NioServerSocketChannel.class)  //指定io模型 nio是 NioServerSocketChannel   BIO是 OioServerSocketChannel
                .childHandler(new ChannelInitializer<NioSocketChannel>() {  //在ServerBootstrap的初始化过程中，会为其添加一个实现了acceptor机制的Handler 这里即ChannelInitializer
                    protected void initChannel(NioSocketChannel ch) {
                        ch.pipeline().addLast(new StringDecoder());
                        ch.pipeline().addLast(new SimpleChannelInboundHandler<String>() {
                            @Override
                            protected void channelRead0(ChannelHandlerContext ctx, String msg) {
                                System.out.println(msg);
                            }
                        });
                    }
                })
                .bind(8000);
//      下面这种绑定的方法可以监听 端口是否绑定成功
//        serverBootstrap.bind(8000).addListener(new GenericFutureListener<Future<? super Void>>() {
//            public void operationComplete(Future<? super Void> future) {
//                if (future.isSuccess()) {
//                    System.out.println("端口绑定成功!");
//                } else {
//                    System.err.println("端口绑定失败!");
//                }
//            }
//        });

    }
}
```

#### 客户端例子

```java
public class NettyClient {
    public static void main(String[] args) throws InterruptedException {
        Bootstrap bootstrap = new Bootstrap();
        NioEventLoopGroup group = new NioEventLoopGroup();

        bootstrap.group(group)
                .channel(NioSocketChannel.class)
                .handler(new ChannelInitializer<Channel>() {
                    @Override
                    protected void initChannel(Channel ch) {
                        ch.pipeline().addLast(new StringEncoder());
                    }
                });
        Channel channel = bootstrap.connect("127.0.0.1", 8000).channel();
        while (true) {
            String str = new Date() + ": hello world!";
            channel.writeAndFlush(str);
            System.out.println("发送: "+str);
            Thread.sleep(2000);
        }
    }
}
```



#### Channel配置参数

- 实测发现有些参数 针对不同的channel, 并不是都好使

```
    CONNECT_TIMEOUT_MILLIS :
      Netty参数，连接超时毫秒数，默认值30000毫秒即30秒。
    MAX_MESSAGES_PER_READ
      Netty参数，一次Loop读取的最大消息数，对于ServerChannel或者NioByteChannel，默认值为16，其他Channel默认值为1。默认值这样设置，是因为：ServerChannel需要接受足够多的连接，保证大吞吐量，NioByteChannel可以减少不必要的系统调用select。
    WRITE_SPIN_COUNT
      Netty参数，一个Loop写操作执行的最大次数，默认值为16。也就是说，对于大数据量的写操作至多进行16次，如果16次仍没有全部写完数据，此时会提交一个新的写任务给EventLoop，任务将在下次调度继续执行。这样，其他的写请求才能被响应不会因为单个大数据量写请求而耽误。
    ALLOCATOR
      Netty参数，ByteBuf的分配器，默认值为ByteBufAllocator.DEFAULT，4.0版本为UnpooledByteBufAllocator，4.1版本为PooledByteBufAllocator。该值也可以使用系统参数io.netty.allocator.type配置，使用字符串值："unpooled"，"pooled"。
    RCVBUF_ALLOCATOR
      Netty参数，用于Channel分配接受Buffer的分配器，默认值为AdaptiveRecvByteBufAllocator.DEFAULT，是一个自适应的接受缓冲区分配器，能根据接受到的数据自动调节大小。可选值为FixedRecvByteBufAllocator，固定大小的接受缓冲区分配器。
    AUTO_READ
      Netty参数，自动读取，默认值为True。Netty只在必要的时候才设置关心相应的I/O事件。对于读操作，需要调用channel.read()设置关心的I/O事件为OP_READ，这样若有数据到达才能读取以供用户处理。该值为True时，每次读操作完毕后会自动调用channel.read()，从而有数据到达便能读取；否则，需要用户手动调用channel.read()。需要注意的是：当调用config.setAutoRead(boolean)方法时，如果状态由false变为true，将会调用channel.read()方法读取数据；由true变为false，将调用config.autoReadCleared()方法终止数据读取。
    WRITE_BUFFER_HIGH_WATER_MARK
      Netty参数，写高水位标记，默认值64KB。如果Netty的写缓冲区中的字节超过该值，Channel的isWritable()返回False。
    WRITE_BUFFER_LOW_WATER_MARK
      Netty参数，写低水位标记，默认值32KB。当Netty的写缓冲区中的字节超过高水位之后若下降到低水位，则Channel的isWritable()返回True。写高低水位标记使用户可以控制写入数据速度，从而实现流量控制。推荐做法是：每次调用channl.write(msg)方法首先调用channel.isWritable()判断是否可写。
    MESSAGE_SIZE_ESTIMATOR
      Netty参数，消息大小估算器，默认为DefaultMessageSizeEstimator.DEFAULT。估算ByteBuf、ByteBufHolder和FileRegion的大小，其中ByteBuf和ByteBufHolder为实际大小，FileRegion估算值为0。该值估算的字节数在计算水位时使用，FileRegion为0可知FileRegion不影响高低水位。
    SINGLE_EVENTEXECUTOR_PER_GROUP
      Netty参数，单线程执行ChannelPipeline中的事件，默认值为True。该值控制执行ChannelPipeline中执行ChannelHandler的线程。如果为Trye，整个pipeline由一个线程执行，这样不需要进行线程切换以及线程同步，是Netty4的推荐做法；如果为False，ChannelHandler中的处理过程会由Group中的不同线程执行。
    (2).SocketChannel参数
    SO_RCVBUF
      Socket参数，TCP数据接收缓冲区大小。该缓冲区即TCP接收滑动窗口，linux操作系统可使用命令：cat /proc/sys/net/ipv4/tcp_rmem查询其大小。一般情况下，该值可由用户在任意时刻设置，但当设置值超过64KB时，需要在连接到远端之前设置。
    SO_SNDBUF
      Socket参数，TCP数据发送缓冲区大小。该缓冲区即TCP发送滑动窗口，linux操作系统可使用命令：cat /proc/sys/net/ipv4/tcp_smem查询其大小。
    TCP_NODELAY
      TCP参数，立即发送数据，默认值为Ture（Netty默认为True而操作系统默认为False）。该值设置Nagle算法的启用，改算法将小的碎片数据连接成更大的报文来最小化所发送的报文的数量，如果需要发送一些较小的报文，则需要禁用该算法。Netty默认禁用该算法，从而最小化报文传输延时。
    SO_KEEPALIVE
      Socket参数，连接保活，默认值为False。启用该功能时，TCP会主动探测空闲连接的有效性。可以将此功能视为TCP的心跳机制，需要注意的是：默认的心跳间隔是7200s即2小时。Netty默认关闭该功能。
    SO_REUSEADDR
      Socket参数，地址复用，默认值False。有四种情况可以使用：(1).当有一个有相同本地地址和端口的socket1处于TIME_WAIT状态时，而你希望启动的程序的socket2要占用该地址和端口，比如重启服务且保持先前端口。(2).有多块网卡或用IP Alias技术的机器在同一端口启动多个进程，但每个进程绑定的本地IP地址不能相同。(3).单个进程绑定相同的端口到多个socket上，但每个socket绑定的ip地址不同。(4).完全相同的地址和端口的重复绑定。但这只用于UDP的多播，不用于TCP。
    SO_LINGER
      Socket参数，关闭Socket的延迟时间，默认值为-1，表示禁用该功能。-1表示socket.close()方法立即返回，但OS底层会将发送缓冲区全部发送到对端。0表示socket.close()方法立即返回，OS放弃发送缓冲区的数据直接向对端发送RST包，对端收到复位错误。非0整数值表示调用socket.close()方法的线程被阻塞直到延迟时间到或发送缓冲区中的数据发送完毕，若超时，则对端会收到复位错误。
    IP_TOS
      IP参数，设置IP头部的Type-of-Service字段，用于描述IP包的优先级和QoS选项。
    ALLOW_HALF_CLOSURE
      Netty参数，一个连接的远端关闭时本地端是否关闭，默认值为False。值为False时，连接自动关闭；为True时，触发ChannelInboundHandler的userEventTriggered()方法，事件为ChannelInputShutdownEvent。
    (3).ServerSocketChannel参数
    SO_RCVBUF
      已说明，需要注意的是：当设置值超过64KB时，需要在绑定到本地端口前设置。该值设置的是由ServerSocketChannel使用accept接受的SocketChannel的接收缓冲区。
    SO_REUSEADDR
      已说明
    SO_BACKLOG
      Socket参数，服务端接受连接的队列长度，如果队列已满，客户端连接将被拒绝。默认值，Windows为200，其他为128。
    (4).DatagramChannel参数
    SO_BROADCAST: Socket参数，设置广播模式。
    SO_RCVBUF: 已说明
    SO_SNDBUF:已说明
    SO_REUSEADDR:已说明
    IP_MULTICAST_LOOP_DISABLED:
      对应IP参数IP_MULTICAST_LOOP，设置本地回环接口的多播功能。由于IP_MULTICAST_LOOP返回True表示关闭，所以Netty加上后缀_DISABLED防止歧义。
    IP_MULTICAST_ADDR:
      对应IP参数IP_MULTICAST_IF，设置对应地址的网卡为多播模式。
    IP_MULTICAST_IF:
      对应IP参数IP_MULTICAST_IF2，同上但支持IPV6。
    IP_MULTICAST_TTL:
      IP参数，多播数据报的time-to-live即存活跳数。
    IP_TOS:
      已说明
    DATAGRAM_CHANNEL_ACTIVE_ON_REGISTRATION:
      Netty参数，DatagramChannel注册的EventLoop即表示已激活。
```

#### netty代码

[nettyTest : https://github.com/super-lihc/nettyTest](https://github.com/super-lihc/nettyTest)

#### 参考

github: https://github.com/netty/netty

官网:	https://netty.io

io发展:	https://www.jianshu.com/p/a4e03835921a

io模式理解: 	https://blog.csdn.net/szxiaohe/article/details/81542605